{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJZCk_YuZK93",
        "outputId": "38a318c8-668b-420f-d371-7f39fff449a4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-1.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R50dNgiy7f4Z"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zvvdnpp4OJD"
      },
      "source": [
        "64 input layer (board)\n",
        "3 hidden layers\n",
        "128\n",
        "64\n",
        "32\n",
        "64x1 probability vector (softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rda7GCzq9d72"
      },
      "outputs": [],
      "source": [
        "class H5OthelloDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for Othello training data stored in HDF5.\n",
        "    Expects each sample in a group named 'sample_{i}' with:\n",
        "      - dataset 'board' (64,) int8 or int32\n",
        "      - dataset 'probs' (64,) float32\n",
        "      - attribute 'outcome' (scalar int)\n",
        "    \"\"\"\n",
        "    def __init__(self, h5_path):\n",
        "        self.h5_path = h5_path\n",
        "        # Open HDF5 file once\n",
        "        self.file = h5py.File(h5_path, 'r')\n",
        "        # List and sort group keys\n",
        "        self.keys = list(self.file.keys())\n",
        "        try:\n",
        "            # if named sample_0, sample_1, ...\n",
        "            self.keys.sort(key=lambda x: int(x.split('_')[1]))\n",
        "        except Exception:\n",
        "            self.keys.sort()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        grp = self.file[self.keys[idx]]\n",
        "        # Load numpy arrays\n",
        "        board_vec = grp['board'][()]    # shape (64,)\n",
        "        pi_vec    = grp['probs'][()]    # shape (64,)\n",
        "        outcome   = grp.attrs['outcome'] # scalar\n",
        "\n",
        "        # Reshape to 8x8 and build 2-channel tensor\n",
        "        board = board_vec.reshape(8, 8)\n",
        "        my_stones  = (board ==  1).astype(np.float32)\n",
        "        opp_stones = (board == -1).astype(np.float32)\n",
        "        x = np.stack([my_stones, opp_stones], axis=0)  # (2,8,8)\n",
        "\n",
        "        # Policy target and legal-mask\n",
        "        pi   = pi_vec.astype(np.float32)               # (64,)\n",
        "        mask = (pi > 0)                                # (64,) bool\n",
        "\n",
        "        # Value target\n",
        "        y_value = np.float32(outcome)\n",
        "\n",
        "        return (\n",
        "            torch.from_numpy(x),               # float32 tensor (2,8,8)\n",
        "            torch.from_numpy(pi),              # float32 tensor (64,)\n",
        "            torch.from_numpy(mask),            # bool tensor (64,)\n",
        "            torch.tensor(y_value)              # float32 scalar\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8v2Fy3aZ260i"
      },
      "outputs": [],
      "source": [
        "class OthelloNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # convolutional trunk\n",
        "        self.trunk = nn.Sequential(\n",
        "            nn.Conv2d(2, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            # add more blocks or residual layers as needed\n",
        "        )\n",
        "        # policy head\n",
        "        self.p_conv = nn.Conv2d(64, 2, kernel_size=1)\n",
        "        self.p_fc   = nn.Linear(2 * 8 * 8, 64)\n",
        "        # value head\n",
        "        self.v_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
        "        self.v_fc1  = nn.Linear(1 * 8 * 8, 64)\n",
        "        self.v_fc2  = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x, legal_mask):\n",
        "        B = x.size(0)\n",
        "        features = self.trunk(x)                 # (B,64,8,8)\n",
        "\n",
        "        # Policy branch\n",
        "        p = F.relu(self.p_conv(features))       # (B,2,8,8)\n",
        "        p = p.view(B, -1)                       # (B,128)\n",
        "        logits = self.p_fc(p)                   # (B,64)\n",
        "\n",
        "        # Value branch\n",
        "        v = F.relu(self.v_conv(features))       # (B,1,8,8)\n",
        "        v = v.view(B, -1)                       # (B,64)\n",
        "        v = F.relu(self.v_fc1(v))               # (B,64)\n",
        "        value = torch.tanh(self.v_fc2(v))       # (B,1)\n",
        "\n",
        "        return logits, value.squeeze(1)      # (B,64), (B,)\n",
        "\n",
        "def train(args):\n",
        "    NEG_INF = -1e9\n",
        "    # (Optionally) turn on anomaly detection for NaN tracing\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # --- Dataset & DataLoader ---\n",
        "    dataset = H5OthelloDataset(args.data)\n",
        "    loader  = DataLoader(\n",
        "        dataset,\n",
        "        batch_size   = args.batch_size,\n",
        "        shuffle      = True,\n",
        "        num_workers  = args.num_workers,\n",
        "        pin_memory   = True\n",
        "    )\n",
        "\n",
        "    # --- Model, Optimizer, Scheduler ---\n",
        "    model = OthelloNet().to(device)\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr           = args.lr,\n",
        "        weight_decay = args.weight_decay\n",
        "    )\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "        optimizer, step_size=args.lr_step, gamma=args.lr_gamma\n",
        "    )\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    os.makedirs(os.path.dirname(args.save_path), exist_ok=True)\n",
        "\n",
        "    # --- Training Loop ---\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        model.train()\n",
        "        total_p_loss = 0.0\n",
        "        total_v_loss = 0.0\n",
        "\n",
        "        pbar = tqdm(loader, desc=f\"Epoch {epoch}/{args.epochs}\")\n",
        "        for x, pi, mask, y in pbar:\n",
        "            # Move to device\n",
        "            x, pi, mask, y = x.to(device), pi.to(device), mask.to(device), y.to(device)\n",
        "            pi = pi * mask.float()\n",
        "            pi = pi / pi.sum(dim=1, keepdim=True).clamp(min=1e-6)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits, v_pred = model(x, mask)              # now really logits\n",
        "            logits = logits.masked_fill(~mask, NEG_INF)  # floor illegal\n",
        "            log_probs = F.log_softmax(logits, dim=1)\n",
        "\n",
        "            p_loss = -(pi * log_probs).sum(dim=1).mean()\n",
        "            v_loss = F.mse_loss(v_pred, y)\n",
        "            loss   = p_loss + args.value_weight * v_loss\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate for reporting\n",
        "            batch_size = x.size(0)\n",
        "            total_p_loss += p_loss.item() * batch_size\n",
        "            total_v_loss += v_loss.item() * batch_size\n",
        "\n",
        "        # 6) LR schedule & metrics\n",
        "        scheduler.step()\n",
        "        N = len(dataset)\n",
        "        avg_p = total_p_loss / N\n",
        "        avg_v = total_v_loss / N\n",
        "        avg_total = avg_p + args.value_weight * avg_v\n",
        "\n",
        "        print(f\"→ Epoch {epoch:2d}: Policy={avg_p:.4f}, Value={avg_v:.4f}, Total={avg_total:.4f}\")\n",
        "\n",
        "        # 7) Save best\n",
        "        if avg_total < best_loss:\n",
        "            best_loss = avg_total\n",
        "            torch.save(model.state_dict(), args.save_path)\n",
        "            print(f\"  ↳ Saved best model to {args.save_path}\")\n",
        "\n",
        "    print(\"✅ Training complete.\")\n",
        "\n",
        "    # --- ONNX Export ---\n",
        "    if args.onnx_path:\n",
        "        os.makedirs(os.path.dirname(args.onnx_path), exist_ok=True)\n",
        "\n",
        "        # Dummy inputs: one board + one mask\n",
        "        dummy_x    = torch.randn(1, 2, 8, 8, device=device)\n",
        "        dummy_mask = torch.ones(1, 64, dtype=torch.bool, device=device)\n",
        "\n",
        "        torch.onnx.export(\n",
        "            model,                                  # model\n",
        "            (dummy_x, dummy_mask),                  # model inputs\n",
        "            args.onnx_path,                         # where to save the ONNX file\n",
        "            export_params=True,                     # store the trained params\n",
        "            opset_version=12,                       # ONNX opset\n",
        "            do_constant_folding=True,               # const‐folding for optimization\n",
        "            input_names=['board', 'legal_mask'],    # input tensor names\n",
        "            output_names=['log_probs', 'value'],    # output tensor names\n",
        "            dynamic_axes={\n",
        "                'board':      {0: 'batch_size'},\n",
        "                'legal_mask': {0: 'batch_size'},\n",
        "                'log_probs':  {0: 'batch_size'},\n",
        "                'value':      {0: 'batch_size'},\n",
        "            }\n",
        "        )\n",
        "        print(f\"✅ Exported ONNX model to {args.onnx_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY-vOqgm9lXL",
        "outputId": "ba260a0b-7953-4a81-8570-ead5a7981978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161,
          "referenced_widgets": [
            "55eb9883b99a4742939e309865d23a61",
            "60d9ed4ae1f84232996fc4d5e1628755",
            "3897b454f10f4c3c9a3ce39627ceac3d",
            "9536c175e60b4e0395929edd45eb4122",
            "0878bd3279ae40c994afb4c34b8ed047",
            "8866c356cdd648f2ae42540188159ddd",
            "bd97f4d6f6f0415688ca1f8b2da0d83e",
            "8848a2cac74747aa9ef1a5a9791d1dea",
            "6d7c423239764bfa9949110a78f1709e",
            "aef5b171a72342b09cd60c9add599dc7",
            "06dc14a276344f43a57630161aa7a914"
          ]
        },
        "id": "TDrvAqNNAEj5",
        "outputId": "faf669ab-a957-46cb-c1fb-e096e5b303c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignored Arg:  ['-f', '/root/.local/share/jupyter/runtime/kernel-2bdc3e7f-36a0-42c4-8a93-4b11a6301fcf.json']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/20:   0%|          | 0/2281 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55eb9883b99a4742939e309865d23a61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    training_set = '/content/drive/MyDrive/training_samples_sample.h5'\n",
        "\n",
        "    p = argparse.ArgumentParser(description=\"Train & export Othello net from HDF5 data\")\n",
        "    p.add_argument(\"--data\",         type=str,   default=training_set,\n",
        "                   help=\"Path to HDF5 file containing training groups\")\n",
        "    p.add_argument(\"--save-path\",    type=str,   default=\"models/othello_h5.pt\",\n",
        "                   help=\"Where to save PyTorch model weights\")\n",
        "    p.add_argument(\"--onnx-path\",    type=str,   default=\"models/othello.onnx\",\n",
        "                   help=\"Where to save ONNX model (set to empty string to skip)\")\n",
        "    p.add_argument(\"--epochs\",       type=int,   default=20)\n",
        "    p.add_argument(\"--batch-size\",   type=int,   default=128)\n",
        "    p.add_argument(\"--num-workers\",  type=int,   default=4)\n",
        "    p.add_argument(\"--lr\",           type=float, default=1e-3)\n",
        "    p.add_argument(\"--weight-decay\", type=float, default=1e-4)\n",
        "    p.add_argument(\"--lr-step\",      type=int,   default=10)\n",
        "    p.add_argument(\"--lr-gamma\",     type=float, default=0.1)\n",
        "    p.add_argument(\"--value-weight\", type=float, default=1.0,\n",
        "                   help=\"λ for value‐loss scaling\")\n",
        "    p.add_argument(\"--device\",       type=str,   default=None,\n",
        "                   help=\"Override device (e.g., 'cpu' or 'cuda:0')\")\n",
        "\n",
        "    args, err = p.parse_known_args()\n",
        "    if err:\n",
        "      print(\"Ignored Arg: \", err)\n",
        "    train(args)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "55eb9883b99a4742939e309865d23a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60d9ed4ae1f84232996fc4d5e1628755",
              "IPY_MODEL_3897b454f10f4c3c9a3ce39627ceac3d",
              "IPY_MODEL_9536c175e60b4e0395929edd45eb4122"
            ],
            "layout": "IPY_MODEL_0878bd3279ae40c994afb4c34b8ed047"
          }
        },
        "60d9ed4ae1f84232996fc4d5e1628755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8866c356cdd648f2ae42540188159ddd",
            "placeholder": "​",
            "style": "IPY_MODEL_bd97f4d6f6f0415688ca1f8b2da0d83e",
            "value": "Epoch 1/20:  38%"
          }
        },
        "3897b454f10f4c3c9a3ce39627ceac3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8848a2cac74747aa9ef1a5a9791d1dea",
            "max": 2281,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d7c423239764bfa9949110a78f1709e",
            "value": 863
          }
        },
        "9536c175e60b4e0395929edd45eb4122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aef5b171a72342b09cd60c9add599dc7",
            "placeholder": "​",
            "style": "IPY_MODEL_06dc14a276344f43a57630161aa7a914",
            "value": " 863/2281 [01:32&lt;02:08, 10.99it/s]"
          }
        },
        "0878bd3279ae40c994afb4c34b8ed047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8866c356cdd648f2ae42540188159ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd97f4d6f6f0415688ca1f8b2da0d83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8848a2cac74747aa9ef1a5a9791d1dea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7c423239764bfa9949110a78f1709e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aef5b171a72342b09cd60c9add599dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06dc14a276344f43a57630161aa7a914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}